### 背景
#### 目前的 MLLM 难以有效地解决细粒度的多模态挑战
### 造成这种现象的原因
#### 视觉编码器有限的空间感知能力和感知敏锐度往往会导致图像中无关背景信息的干扰，导致模型忽略细微但至关重要的细节
#### 目前的 MLLM 容易受到背景噪声的影响或者试图从文本提示中寻找答案，放大了语言先验的影响
### 本文所提方法的灵感
#### 为了理解复杂的视觉信息，人类通常关注给定样本中的特定区域或细节。当被问及提供一个局部区域的详细描述或者询问一个小目标物体的属性时，人类一般会扫描整幅图像，定位目标的大致位置，然后集中精力于此。
### 所提方法 CoF
#### 链式思考：直接指导模型的输入和输出；所提方法：在潜变量空间中操作
#### 双阶段：
1、粗粒度定位锚定：识别给定图像中的目标区域（促使 MLLM 确定目标区域的坐标）  
2、细粒度注意力重加权：理解目标区域的语义信息（为该区域中的视觉 token 分配更高的注意力权重）  
#### 粗粒度定位锚定
给定图像 $I$ 和问题 $Q$，手动设定锚定提示 $P_g$。引导 MLLM 识别出图像中与问题相关的大致区域，并输出其对应的 bounding box 坐标  
“According to the information in the image and the question, detail the bounding box of the region in the image that contains the answer in JSON format.”  
得到答案区域的坐标后，执行一个后处理步骤，旨在优化这个输出：
确定包围盒的中心坐标，引入了一个扩展的超参数 α 调整包围盒，规定包围盒应该扩展到的合适大小
